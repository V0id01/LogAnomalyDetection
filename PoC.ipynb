{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-portable",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from drain3 import TemplateMiner\n",
    "from drain3.drain import LogCluster\n",
    "from fastai import *\n",
    "from fastai.text.all import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fasttext\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "\n",
    "# IntelÂ® Extension for Scikit-learn\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline, make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "projectRoot = Path(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-junction",
   "metadata": {},
   "source": [
    "# Import data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-treasurer",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = projectRoot/'data/BGL.csv'\n",
    "df = pd.read_csv(dataset_file)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-catch",
   "metadata": {},
   "source": [
    "# Create log sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-permit",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-hanging",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = math.floor(df['logs'].index.size/WINDOW_SIZE)\n",
    "r = df['logs'].index.size % WINDOW_SIZE\n",
    "if r != 0:\n",
    "    # Cut off not divisible part\n",
    "    seqs = np.array(np.split(np.array(df['logs'])[:-r], n))\n",
    "else:\n",
    "    seqs = np.array(np.split(np.array(df['logs']), n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-botswana",
   "metadata": {},
   "source": [
    "# Create labels for sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = math.floor(len(df.index)/WINDOW_SIZE)\n",
    "r = len(df.index) % WINDOW_SIZE\n",
    "if r != 0:\n",
    "    # Cut off not divisible part\n",
    "    seqs_idx = np.array(np.split(df.index.to_numpy()[:-r], n))\n",
    "else:\n",
    "    seqs_idx = np.array(np.split(df.index.to_numpy(), n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-leader",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.empty([n], dtype=int)\n",
    "i = 0\n",
    "for seq in seqs_idx:\n",
    "    if np.sum(df.loc[seq]['anomaly_labels'].values.astype(int)) > 0:\n",
    "        y[i] = 1\n",
    "    else:\n",
    "        y[i] = 0\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-nurse",
   "metadata": {},
   "source": [
    "# Create pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-screw",
   "metadata": {},
   "source": [
    "## Parsing and numericalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-melbourne",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parsing(BaseEstimator, TransformerMixin):    \n",
    "    def __init__(self):\n",
    "        self.persistence_type = None\n",
    "        self.template_miner = TemplateMiner(self.persistence_type)\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        seqs_list = X.reshape([-1]).tolist()\n",
    "        for line in tqdm(self.extract_description(seqs_list)):\n",
    "            self.template_miner.add_log_message(line)\n",
    "        self.add_wildcard_template()\n",
    "        self.max_clusters_size = self.template_miner.drain.clusters_counter\n",
    "        print(f'Number of created templates: {self.max_clusters_size}')\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        seqs_list = X.reshape([-1]).tolist()\n",
    "        self.parsed = []\n",
    "        i = 0\n",
    "        for line in tqdm(self.extract_description(seqs_list)):\n",
    "            self.parsed.append(self.template_miner.add_log_message(line))\n",
    "            if self.template_miner.drain.clusters_counter > self.max_clusters_size:\n",
    "                self.delete_unknown_templates()\n",
    "                #print('Deleted unknown template')\n",
    "                i += 1\n",
    "        print(f'Number of deleted unknown templates: {i}')\n",
    "        # Numericalize\n",
    "        nums = self.numericalize([x['template_mined'] for x in self.parsed])\n",
    "        # Create sequences\n",
    "        n = math.floor(len(nums)/WINDOW_SIZE)\n",
    "        nums = np.array(np.split(nums, n))\n",
    "        return nums\n",
    "    \n",
    "    def extract_description(self, l):\n",
    "        r = re.compile('(?<= )(?:APP|KERNEL|LINKCARD|DISCOVERY|HARDWARE|CMCS|MMCS|BGLMASTER|MONITOR|SERV_NET) (?:WARNING|INFO|ERROR|FATAL|FAILURE|SEVERE)(?: {0,1})(.*$)')\n",
    "        nl = [match.group(1) \n",
    "              if (match := r.search(ll))\n",
    "              else ''\n",
    "              for ll in l] # Adds empty string if log has no description\n",
    "        return nl\n",
    "    \n",
    "    def add_wildcard_template(self):\n",
    "        self.template_miner.drain.clusters_counter += 1\n",
    "        cluster_id = self.template_miner.drain.clusters_counter\n",
    "        match_cluster = LogCluster(['<*>'], cluster_id)\n",
    "        self.template_miner.drain.id_to_cluster[cluster_id] = match_cluster\n",
    "        self.template_miner.drain.add_seq_to_prefix_tree(self.template_miner.drain.root_node, match_cluster)\n",
    "        max_clusters_size = self.template_miner.drain.clusters_counter\n",
    "        self.template_miner.drain.id_to_cluster[max_clusters_size].size = 0\n",
    "\n",
    "    def delete_unknown_templates(self):\n",
    "        del self.parsed[-1]\n",
    "        del self.template_miner.drain.id_to_cluster[self.template_miner.drain.clusters_counter]\n",
    "        self.template_miner.drain.clusters_counter -= 1\n",
    "        self.template_miner.drain.id_to_cluster[self.max_clusters_size].size += 1\n",
    "        self.parsed.append(\n",
    "        {\n",
    "            \"change_type\": 'none',\n",
    "            \"cluster_id\": self.max_clusters_size,\n",
    "            \"cluster_size\": self.template_miner.drain.id_to_cluster[self.max_clusters_size].size,\n",
    "            \"template_mined\": self.template_miner.drain.id_to_cluster[self.max_clusters_size].get_template(),\n",
    "            \"cluster_count\": len(self.template_miner.drain.clusters)\n",
    "        })\n",
    "        \n",
    "    def numericalize(self, X):\n",
    "        vocab = [cluster.get_template() for cluster in self.template_miner.drain.clusters]\n",
    "        num = Numericalize(vocab, min_freq=1)\n",
    "        num.setup()\n",
    "        return np.array(num(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-treasurer",
   "metadata": {},
   "source": [
    "# Word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordEmbedding(BaseEstimator, TransformerMixin):    \n",
    "    def __init__(self):\n",
    "        self.NUMBER_OF_DIMENSIONS = 100\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        random_int = random.randint(0,10000)\n",
    "        file_path = 'data/BGL/BGL_train_seqs'+str(random_int)+'.txt'\n",
    "        np.savetxt(projectRoot/file_path, X.astype(int), fmt='%i')\n",
    "        self.fasttext_model = fasttext.train_unsupervised(file_path, model='cbow', minCount=1, dim=self.NUMBER_OF_DIMENSIONS, maxn=0)\n",
    "        os.remove(projectRoot/file_path)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        X_ = X.copy() # creating a copy to avoid changes to original dataset\n",
    "        X_ = np.apply_along_axis(self.average_embeddings, 1, X_)\n",
    "        return X_\n",
    "    \n",
    "    def average_embeddings(self, num_lse_vector):\n",
    "        '''\n",
    "        Calculate FastText word representation vector by averaging embeddings in log sequence.\n",
    "        Example input: train_set_s[0] ['3', '3', '3', '3', '3', '3', '2', '2', '12', '3' ...] (length == WINDOW_SIZE)\n",
    "        '''\n",
    "        w2v_vector = [self.fasttext_model.get_word_vector(word) for word in np.vectorize(str)(num_lse_vector)]\n",
    "        return np.average(w2v_vector, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-confidence",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-circular",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07013461",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train, test in cv.split(seqs, y):\n",
    "    print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-rochester",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (auc, roc_curve, average_precision_score, precision_recall_curve, f1_score, accuracy_score,\n",
    "                            recall_score, precision_score)\n",
    "\n",
    "y_real = []\n",
    "y_proba = []\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "avg_precisions = []\n",
    "\n",
    "tprs = []\n",
    "tprs2 = []\n",
    "fprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "f1_scores = []\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "i = 0\n",
    "for train, test in cv.split(seqs, y):\n",
    "#RF\n",
    "#     pipe = Pipeline(steps=[\n",
    "#                        ('parsing', Parsing()),\n",
    "#                        ('word_embedding', WordEmbedding()),\n",
    "#                        ('random_forest', RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1))\n",
    "#     ])\n",
    "#     classifier_name = 'RF'\n",
    "# MLP\n",
    "#     pipe = Pipeline(steps=[\n",
    "#                        ('parsing', Parsing()),\n",
    "#                        ('word_embedding', WordEmbedding()),\n",
    "#                        ('mlp', MLPClassifier(random_state=0))\n",
    "#     ])\n",
    "#     classifier_name = 'MLP'\n",
    "# GNB\n",
    "    pipe = Pipeline(steps=[\n",
    "                       ('parsing', Parsing()),\n",
    "                       ('word_embedding', WordEmbedding()),\n",
    "                       ('gnb', GaussianNB())\n",
    "    ])\n",
    "    classifier_name = 'GNB'\n",
    "# Ada Boost\n",
    "#    pipe = Pipeline(steps=[\n",
    "#                      ('parsing', Parsing()),\n",
    "#                      ('word_embedding', WordEmbedding()),\n",
    "#                      ('adaboost', AdaBoostClassifier(n_estimators=100, random_state=0))\n",
    "#    ])\n",
    "#    classifier_name = 'AB'\n",
    "# DT\n",
    "#     pipe = Pipeline(steps=[\n",
    "#                         ('parsing', Parsing()),\n",
    "#                         ('word_embedding', WordEmbedding()),\n",
    "#                         ('decision_tree', DecisionTreeClassifier(random_state=0))\n",
    "#     ])\n",
    "#     classifier_name = 'DT'\n",
    "# XGBoost\n",
    "#     total_negative_examples = (y == 0).sum()\n",
    "#     total_positive_examples = (y == 1).sum()\n",
    "#     ratio = total_negative_examples / total_positive_examples\n",
    "#     pipe = Pipeline(steps=[\n",
    "#                          ('parsing', Parsing()),\n",
    "#                          ('word_embedding', WordEmbedding()),\n",
    "#                          ('xgboost', XGBClassifier(use_label_encoder=False,\n",
    "#                                                    objective='binary:logistic',\n",
    "#                                                    eval_metric='logloss',\n",
    "#                                                    scale_pos_weight=ratio))\n",
    "#     ])\n",
    "#     classifier_name = 'XB'\n",
    "    probas_ = pipe.fit(seqs[train], y[train]).predict_proba(seqs[test])\n",
    "    \n",
    "    ####### PR #######\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(y[test], probas_[:, 1])\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    \n",
    "    avg_precision = average_precision_score(y[test], probas_[:, 1])\n",
    "    avg_precisions.append(avg_precision)\n",
    "        \n",
    "    y_real.append(y[test])\n",
    "    y_proba.append(probas_[:, 1])\n",
    "    \n",
    "    ####### ROC #######\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y[test], probas_[:, 1])\n",
    "    tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "    tprs2.append(tpr)\n",
    "    fprs.append(fpr)\n",
    "        \n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    \n",
    "    ####### F1-score, Accuracy, Precision and Recall #######\n",
    "    \n",
    "    y_pred = pipe.predict(seqs[test])\n",
    "    \n",
    "    f1_scores.append(f1_score(y[test], y_pred))\n",
    "    accuracy_scores.append(accuracy_score(y[test], y_pred))\n",
    "    precision_scores.append(precision_score(y[test], y_pred))\n",
    "    recall_scores.append(recall_score(y[test], y_pred))\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "y_real = np.concatenate(y_real)\n",
    "y_proba = np.concatenate(y_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fdca10",
   "metadata": {},
   "source": [
    "## Saving results to pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-flour",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['recalls', 'precisions', 'avg_precisions',\n",
    "           'y_real', 'y_proba', 'aucs', 'fprs', 'tprs', \n",
    "           'tprs2', 'f1_scores', 'accuracy_scores',\n",
    "            'precision_scores', 'recall_scores']\n",
    "\n",
    "for variable_name in variables:\n",
    "    filepath = 'results/'+str(WINDOW_SIZE)+'/'+classifier_name+'/'+variable_name+'.pickle'\n",
    "    with open(projectRoot/filepath, 'wb') as f:\n",
    "        pickle.dump(globals()[variable_name], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9249fbdb",
   "metadata": {},
   "source": [
    "## PR curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-import",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# PR plots\n",
    "plt.figure(1, dpi=100)\n",
    "\n",
    "for i in range(len(avg_precisions)):\n",
    "    plt.plot(recalls[i], precisions[i], lw=1, alpha=0.3,\n",
    "             label='PR fold %d (AUC = %0.5f)' % (i, avg_precisions[i]))\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_real, y_proba)\n",
    "plt.plot(recall, precision, color='b',\n",
    "             label=r'Mean PR (AUC = %0.5f)' % (average_precision_score(y_real, y_proba)),\n",
    "             lw=2, alpha=.8)\n",
    "    \n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([0.05, 1.05])\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Recall')\n",
    "plt.title('PR Curve')\n",
    "plt.legend(loc=\"lower left\", prop={'size': 9})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-sydney",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PR plots\n",
    "plt.figure(1, dpi=100)\n",
    "\n",
    "for i in range(len(avg_precisions)):\n",
    "    plt.plot(recalls[i], precisions[i], lw=1, alpha=0.3,\n",
    "             label='PR fold %d (AUC = %0.5f)' % (i, avg_precisions[i]))\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_real, y_proba)\n",
    "plt.plot(recall, precision, color='b',\n",
    "             label=r'Mean PR (AUC = %0.5f)' % (average_precision_score(y_real, y_proba)),\n",
    "             lw=2, alpha=.8)\n",
    "    \n",
    "plt.xlim([0.85, 1.05])\n",
    "plt.ylim([0.3, 1.05])\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Recall')\n",
    "plt.title('PR Curve')\n",
    "plt.legend(loc=\"lower left\", prop={'size': 9})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed76aa27",
   "metadata": {},
   "source": [
    "## ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-breast",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ROC plots\n",
    "plt.figure(2, dpi=100)\n",
    "\n",
    "for i in range(len(aucs)):\n",
    "    plt.plot(fprs[i], tprs2[i], lw=1, alpha=0.3,\n",
    "             label='ROC fold %d (AUC = %0.4f)' % (i, aucs[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "             label='Luck', alpha=.8)\n",
    "    \n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.4f $\\pm$ %0.4f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                     label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\", prop={'size': 8})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-nowhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC plots\n",
    "plt.figure(2, dpi=100)\n",
    "\n",
    "for i in range(len(aucs)):\n",
    "    plt.plot(fprs[i], tprs2[i], lw=1, alpha=0.3,\n",
    "             label='ROC fold %d (AUC = %0.4f)' % (i, aucs[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "             label='Luck', alpha=.8)\n",
    "    \n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.4f $\\pm$ %0.4f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                     label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.05, 0.4])\n",
    "plt.ylim([0.4, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\", prop={'size': 8})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ac1353",
   "metadata": {},
   "source": [
    "## Average evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45a85ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'PR AUC: {average_precision_score(y_real, y_proba)}')\n",
    "print(f'ROC AUC: {mean_auc}')\n",
    "print(f'Accuracy: {np.mean(accuracy_scores)}')\n",
    "print(f'F1-score: {np.mean(f1_scores)}')\n",
    "print(f'Precision: {np.mean(precision_scores)}')\n",
    "print(f'Recall: {np.mean(recall_scores)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
